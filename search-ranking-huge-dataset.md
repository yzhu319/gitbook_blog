# Search-ranking: huge dataset

Intro

When the data is huge and stored in multiple clusters, we can use Spark computing framework. For machine learning tasks, we will then use frameworks designed for Spark, like MMLSpark \(Microsoft Machine Learning for Apache Spark\). MMLSpark integrates Spark ML pipelines with LightGBM, enabling highly-scalable solutions to ML training jobs. 

MMLSpark requires Scala 2.11, Spark 2.4+, and Python 3.5+. It has API in[ Scala](https://mmlspark.blob.core.windows.net/docs/1.0.0-rc3/scala/index.html#package) and[ PySpark](https://mmlspark.blob.core.windows.net/docs/1.0.0-rc3/pyspark/index.html)

